{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar-maheshwari01/python.assignment/blob/main/REGRESSION_ASSIGNMENTpw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **REGRESSION ASSIGNMENT**"
      ],
      "metadata": {
        "id": "jPeW59psFLTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q1. What is Simple Linear Regression?**\n",
        "\n",
        "Ans: Simple Linear Regression attempts to determine the strength and characteristics of the relationship between one independent variable (x) and another dependent variable (y).\n",
        "\n",
        "## **Q2. What are the key assumptions of Simple Linear Regression?**\n",
        "\n",
        "Ans: The key assumptions of Simple Linear Regression are:\n",
        "\n",
        "1. **Linearity:** The dependent and independent variables have a linear relationship.If the relationship between the variables is not linear, the regression model will be less accurate.\n",
        "\n",
        "2. **Independence:** The observations in the model are independent of each other.It means that the value of the dependent variable for one observation should not be influenced by the values of other observations.\n",
        "\n",
        "3. **Homoscedasticity:** The variability of residuals is consistent across all levels of the independent variable.If the variability of residuals is not consistent, the regression coefficient estimates will have increased variance.\n",
        "\n",
        "4. **Normality:** The residuals are distributed symmetrically around zero, with no skewness or kurtosis.If the residuals are not normally distributed, the model may not capture the main patterns in the data\n",
        "\n",
        "5. **Multicollinearity:** There is no correlation between the independent variables. If there is correlation between the independent variables, the model will be more complex.\n",
        "\n",
        "# **Q3. What does the coeffient (m) represent in the equation Y=mX+c ?**\n",
        "\n",
        "Ans: The coeffient ' m ' represents the slope of the line which is obtained by:\n",
        "\n",
        "(Y2-Y1)/(X2-X1)\n",
        "\n",
        "# **Q4. What does the coeffient (C) represent in the equation Y=mX+c ?**\n",
        "\n",
        "Ans: In the equation Y=mX+c, the coefficient 'c'represents the y-intercept of the line. This is the value of Y when X=0.\n",
        "\n",
        "# **Q5. How do we calculate the slope 'm' in Simple Linear Regression?**\n",
        "\n",
        "Ans: The slope 'm' in Simple Linear Regression is calculate by the following formula:\n",
        "\n",
        "m=(Y2-Y1)/(X2-X1)\n",
        "\n",
        "# **Q6. What is the purpose of the least squares method in Simple Linear Regression?**\n",
        "\n",
        "Ans: The least squares method is a statistical technique used in Simple Linear Regression to find the best-fitting line through the data points. Its primary purpose is to minimize the difference between the actual data points and the values predicted by the regression line.\n",
        "\n",
        "Raw residuals can be positive or negative, and if they were summed, they might cancel each other out. Squaring ensures all errors contribute positively to the total.\n",
        "\n",
        "# **Q7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?**\n",
        "\n",
        "Ans: In Simple Linear Regression, the coefficient of determination (R²) is a statistical measure that helps you understand the percentage of variation in 'Y' (dependent variable) explained by 'X' (independent variable).\n",
        "\n",
        "R²= Explained Variance / Total Variance\n",
        "\n",
        "OR\n",
        "\n",
        "R²=1-(Residual Variance (SSE) / Total Variance (SST))\n",
        "\n",
        "**Explained Variance:** The variance in Y that is explained by the model.\n",
        "\n",
        "**Residual Variance (SSE):** The variance in Y that is not explained by the model (i.e., the errors).\n",
        "\n",
        "**Total Variance (SST):** The total variance in Y, which includes both the explained and unexplained variance.\n",
        "\n",
        "\n",
        "**R² ranges from 0 to 1:**\n",
        "\n",
        "R² = 0: The independent variable (X) explains none of the variation in the dependent variable (Y). The model has no predictive power.\n",
        "\n",
        "R² = 1: The independent variable (X) explains all the variation in the dependent variable (Y). The model perfectly fits the data.\n",
        "\n",
        "0 < R² < 1: The model explains some proportion of the variability in Y, with a higher R² indicating a better fit.\n",
        "\n"
      ],
      "metadata": {
        "id": "pUMI8f-yFVDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q8. What is Multiple Linear Regression ?**\n",
        "\n",
        "Ans: Multiple Linear Regression (MLR) is an extension of simple linear regression that models the relationship between a dependent variable (Y) and two or more independent variables (X₁, X₂, ..., Xₖ). It assumes a linear relationship between the dependent variable and the independent variables, but unlike simple linear regression, which deals with just one independent variable, MLR handles multiple predictors.\n",
        "\n",
        "## **Q9. What is the main difference between Simpler Linear Regression and Multiple Linear Regression ?**\n",
        "\n",
        "Ans : The primary difference between Simple Linear Regression and Multiple Linear Regression lies in the number of independent variables (predictors) used to predict the dependent variable.\n",
        "\n",
        "In Simple Linear Regression, one independent variable (X) is used to predict the dependent variable (Y).\n",
        "Model Type : Straight line (linear equation).\n",
        "\n",
        "In Multiple Linear Regression, two or more than two independent variables (X₁, X₂, ..., Xₖ) are used to predict the dependent variable (Y).\n",
        "Model Type : Hyperplane (plane in multidimensional space).\n",
        "\n",
        "## **Q10. What are the key assumptions of Multiple Linear Regression?**\n",
        "\n",
        "Ans: Multiple Linear Regression (MLR) assumes the following:\n",
        "\n",
        "1. Linearity: The relationship between the dependent variable (y) and each independent variable (x) should be linear.\n",
        "\n",
        "2. Independence: Each observation should be independent of the others. This means that the errors (residuals) should not be correlated with each other.\n",
        "\n",
        "3. Homoscedasticity: The variance of the errors (residuals) should be constant across all levels of the independent variables.\n",
        "\n",
        "4. Normality: The errors (residuals) should be normally distributed. This can be checked using plots such as Q-Q plots or histograms.\n",
        "\n",
        "5. No multicollinearity: The independent variables should not be highly correlated with each other. This can be checked using correlation matrices or Variance Inflation Factor (VIF) scores.\n",
        "\n",
        "6. No auto-correlation: The errors (residuals) should not be auto-correlated, meaning that the errors at one observation should not be related to the errors at another observation.\n",
        "\n",
        "7. Constant variance: The variance of the errors (residuals) should be constant across all observations.\n",
        "\n",
        "8. No outliers: There should be no outliers in the data, as these can affect the estimates of the model parameters.\n",
        "\n",
        "9. No measurement error: The independent variables should be measured without error.\n",
        "\n",
        "# **Q11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression mode?**\n",
        "\n",
        "Ans:Heteroscedasticity is a statistical concept that refers to the phenomenon where the variance of the error term (residuals) in a regression model changes across different levels of the independent variable(s). In other words, the spread of the residuals is not constant across all levels of the independent variable(s).\n",
        "\n",
        "Heteroscedasticity can affect the results of a Multiple Linear Regression (MLR) model in several ways:\n",
        "\n",
        "1. Inefficient estimates: Heteroscedasticity can lead to inefficient estimates of the model parameters, which can result in incorrect predictions and conclusions.\n",
        "\n",
        "2. Biased standard errors: Heteroscedasticity can cause the standard errors of the model parameters to be biased, which can lead to incorrect inference and hypothesis testing.\n",
        "\n",
        "3. Incorrect hypothesis testing: Heteroscedasticity can affect the validity of hypothesis tests, such as the F-test and t-tests, which can lead to incorrect conclusions about the relationships between the variables.\n",
        "\n",
        "4. Reduced model fit: Heteroscedasticity can reduce the fit of the model, as measured by metrics such as R-squared, which can make it more difficult to identify meaningful relationships between the variables.\n",
        "\n",
        "\n",
        "# **Q12. How can you improve a Multiple Linear Regression model with high multicollinearity?**\n",
        "\n",
        "Ans: Multicollinearity occurs when two or more independent variables in a Multiple Linear Regression (MLR) model are highly correlated with each other. This can cause problems with the model, such as unstable estimates of the regression coefficients, inflated variance of the regression coefficients, and reduced accuracy of predictions.\n",
        "\n",
        "Here are some ways to improve an MLR model with high multicollinearity:\n",
        "\n",
        "1. Remove highly correlated variables: Identify the variables that are highly correlated with each other and remove one of them from the model. This can help reduce multicollinearity and improve the stability of the model.\n",
        "\n",
        "2. Use dimensionality reduction techniques: Techniques such as Principal Component Analysis (PCA) or Partial Least Squares (PLS) can be used to reduce the number of independent variables in the model while retaining most of the information.\n",
        "\n",
        "3. Use regularization techniques: Regularization techniques such as Ridge regression or Lasso regression can be used to reduce the impact of multicollinearity on the model.\n",
        "\n",
        "4. Use a different model specification: Consider using a different model specification, such as a generalized linear model or a generalized additive model, which may be less sensitive to multicollinearity.\n",
        "\n",
        "5. Collect more data: Collecting more data can help reduce multicollinearity by providing more information about the relationships between the variables.\n",
        "\n",
        "6. Use a correlation matrix: Use a correlation matrix to identify the variables that are highly correlated with each other and consider removing one of them from the model.\n",
        "\n",
        "7. Use Variance Inflation Factor (VIF): Use VIF to identify the variables that are highly correlated with each other and consider removing one of them from the model.\n",
        "\n",
        "8. Use a stepwise regression: Use a stepwise regression to select the most important variables in the model and remove the variables that are not significant.\n",
        "\n",
        "\n",
        "# **Q13.What are some common techniques for transforming categorical variables for use in regression models?**\n",
        "\n",
        "Ans:\n",
        "\n",
        "1. One-Hot Encoding (OHE)\n",
        "\n",
        "One-hot encoding is a technique where each category of the categorical variable is represented as a binary vector.\n",
        "\n",
        "2. Label Encoding\n",
        "\n",
        "Label encoding is a technique where each category of the categorical variable is assigned a unique integer value.\n",
        "\n",
        "3. Dummy Variables\n",
        "\n",
        "Dummy variables are similar to one-hot encoding, but we drop one category to avoid multicollinearity.\n",
        "\n",
        "4. Effect Coding\n",
        "\n",
        "Effect coding is a technique where each category of the categorical variable is represented as a vector of values that sum to zero.\n",
        "\n",
        "5. Helmert Coding\n",
        "\n",
        "Helmert coding is a technique where each category of the categorical variable is represented as a vector of values that compare each category to the previous category.\n",
        "\n",
        "\n",
        "# **Q14. What is the role of interaction terms in Multiple Linear Regression?**\n",
        "\n",
        "Ans: Interaction terms in Multiple Linear Regression (MLR) play a crucial role in modeling the relationships between variables. An interaction term represents the joint effect of two or more independent variables on the dependent variable.\n",
        "\n",
        "Role of interaction terms:\n",
        "\n",
        "1. Modeling complex relationships: Interaction terms allow you to model complex relationships between variables, where the effect of one variable on the dependent variable depends on the level of another variable.\n",
        "\n",
        "2. Capturing non-additive effects: Interaction terms capture non-additive effects, where the combined effect of two or more variables is different from the sum of their individual effects.\n",
        "\n",
        "3. Improving model fit: Including interaction terms can improve the fit of the model, especially when there are significant interactions between variables.\n",
        "\n",
        "4. Enhancing interpretability: Interaction terms can provide insights into how variables interact with each other, which can be useful for understanding complex relationships.\n",
        "\n",
        "\n",
        "# **Q15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?**\n",
        "\n",
        "Ans: The interpretation of the intercept can differ between Simple and Multiple Linear Regression due to the differences in the models and the relationships between the variables.\n",
        "\n",
        "**Simple Linear Regression:**\n",
        "\n",
        "In Simple Linear Regression, the intercept represents the expected value of the dependent variable (y) when the independent variable (x) is equal to zero. This is because the model equation is:\n",
        "\n",
        "y = β0 + β1x + ε\n",
        "\n",
        "where β0 is the intercept, β1 is the slope, and ε is the error term.\n",
        "\n",
        "For example, if we have a simple linear regression model that predicts the relationship between the number of hours studied (x) and the exam score (y), the intercept might represent the expected exam score for a student who does not study at all (i.e., x = 0).\n",
        "\n",
        "Multiple Linear Regression:\n",
        "\n",
        "In Multiple Linear Regression, the intercept represents the expected value of the dependent variable (y) when all the independent variables (x1, x2, ..., xn) are equal to zero. This is because the model equation is:\n",
        "\n",
        "y = β0 + β1x1 + β2x2 + … + βnxn + ε\n",
        "\n",
        "where β0 is the intercept, β1, β2, …, βn are the slopes, and ε is the error term.\n",
        "\n",
        "For example, if we have a multiple linear regression model that predicts the relationship between the number of hours studied (x1), the number of practice problems completed (x2), and the exam score (y), the intercept might represent the expected exam score for a student who does not study at all (i.e., x1 = 0) and does not complete any practice problems (i.e., x2 = 0).\n",
        "\n",
        "Key differences:\n",
        "\n",
        "1. Number of variables: Simple Linear Regression has only one independent variable, while Multiple Linear Regression has multiple independent variables.\n",
        "\n",
        "2. Intercept interpretation: In Simple Linear Regression, the intercept represents the expected value of the dependent variable when the independent variable is equal to zero. In Multiple Linear Regression, the intercept represents the expected value of the dependent variable when all independent variables are equal to zero.\n",
        "\n",
        "3. Relationship between variables: Simple Linear Regression assumes a linear relationship between the independent variable and the dependent variable. Multiple Linear Regression assumes a linear relationship between each independent variable and the dependent variable, while controlling for the effects of other independent variables.\n",
        "\n",
        "\n",
        "## **Q16. What is the significance of the slope in regression analysis, and how does it affect predictions?**\n",
        "\n",
        "Ans: The slope in regression analysis represents the change in the dependent variable (y) for a one-unit change in the independent variable (x), while holding all other independent variables constant. The slope is a measure of the strength and direction of the linear relationship between the variables.\n",
        "\n",
        "**Significance of the slope:**\n",
        "\n",
        "1. Direction of the relationship: The sign of the slope (positive or negative) indicates the direction of the relationship between the variables.\n",
        "\n",
        "2. Strength of the relationship: The magnitude of the slope indicates the strength of the relationship between the variables.\n",
        "\n",
        "3. Predictive power: The slope is used to make predictions about the dependent variable based on the independent variable(s).\n",
        "\n",
        "\n",
        "**Effects of the slope on predictions:**\n",
        "\n",
        "1. Positive slope: A positive slope indicates that as the independent variable increases, the dependent variable also increases. Predictions will be higher for higher values of the independent variable.\n",
        "\n",
        "2. Negative slope: A negative slope indicates that as the independent variable increases, the dependent variable decreases. Predictions will be lower for higher values of the independent variable.\n",
        "\n",
        "3. Steep slope: A steep slope indicates a strong relationship between the variables. Small changes in the independent variable will result in large changes in the dependent variable.\n",
        "\n",
        "4. Shallow slope: A shallow slope indicates a weak relationship between the variables. Large changes in the independent variable will result in small changes in the dependent variable.\n",
        "\n",
        "\n",
        "## **Q17. How does the intercept in a regression model provide context for the relationship between variables?**\n",
        "\n",
        "Ans: The intercept in a regression model provides context for the relationship between variables in several ways:\n",
        "\n",
        "**Interpretation of the Intercept**\n",
        "\n",
        "1. Starting point: The intercept represents the expected value of the dependent variable when all independent variables are equal to zero. This provides a starting point for understanding the relationship between the variables.\n",
        "\n",
        "2. Baseline value: The intercept can be thought of as a baseline value for the dependent variable. It represents the value of the dependent variable when none of the independent variables are present.\n",
        "\n",
        "3. Reference point: The intercept serves as a reference point for evaluating the effects of the independent variables on the dependent variable.\n",
        "\n",
        "**Context for the Relationship**\n",
        "\n",
        "1. Direction of the relationship: The intercept can indicate the direction of the relationship between the variables. A positive intercept suggests that the dependent variable tends to be positive even when the independent variables are zero.\n",
        "\n",
        "2. Strength of the relationship: The magnitude of the intercept can provide insight into the strength of the relationship between the variables. A large intercept may indicate a strong relationship.\n",
        "\n",
        "3. Interactions between variables: The intercept can be affected by interactions between independent variables. A significant intercept may indicate that the relationship between the variables is influenced by interactions.\n",
        "\n",
        "## **Q18. What are the limitations of using R² as a sole measure of model performance?**\n",
        "\n",
        "Ans: R² (R-squared or coefficient of determination) is a widely used metric to evaluate the performance of a regression model. However, relying solely on R² has several limitations:\n",
        "\n",
        "**Limitations of R²**\n",
        "\n",
        "1. Overfitting: R² can be misleading when the model is overfitting. A high R² value does not necessarily mean the model is generalizing well.\n",
        "\n",
        "2. Model Complexity: R² does not account for model complexity. A more complex model with more parameters may have a higher R² value, but may not be the best choice.\n",
        "\n",
        "3. Non-Normal Residuals: R² assumes normality of residuals. If residuals are not normally distributed, R² may not accurately reflect model performance.\n",
        "\n",
        "4. Non-Constant Variance: R² assumes constant variance of residuals. If variance is not constant, R² may not accurately reflect model performance.\n",
        "\n",
        "5. Lack of Interpretability: R² is a relative measure, making it difficult to interpret in isolation. A high R² value may not necessarily mean the model is performing well in absolute terms.\n",
        "\n",
        "6. Sensitivity to Outliers: R² is sensitive to outliers, which can greatly impact the value.\n",
        "\n",
        "7. Ignores Prediction Intervals: R² only evaluates the model's ability to explain variance, not its ability to make accurate predictions with confidence intervals.\n",
        "\n",
        "\n",
        "\n",
        "## **Q19. How would you interpret a large standard error for a regression coefficient?**\n",
        "\n",
        "Ans: A large standard error for a regression coefficient indicates that the estimate of the coefficient is uncertain and may not be reliable.\n",
        "\n",
        " Here are some possible interpretations:\n",
        "\n",
        "1. Imprecision in the estimate:\n",
        "\n",
        "A large standard error means that the confidence interval for the coefficient is wide, indicating that the true value of the coefficient could be quite different from the estimated value.\n",
        "\n",
        "2. High variability in the data:\n",
        "\n",
        "A large standard error can be a sign of high variability in the data, making it difficult to estimate the coefficient precisely.\n",
        "\n",
        "3. Multicollinearity:\n",
        "\n",
        "If the independent variables are highly correlated with each other (multicollinearity), it can lead to large standard errors for the coefficients.\n",
        "\n",
        "4. Overfitting:\n",
        "\n",
        "A large standard error can be a sign of overfitting, where the model is too complex and fits the noise in the data rather than the underlying pattern.\n",
        "\n",
        "5. Insufficient data:\n",
        "\n",
        "A large standard error can also indicate that there is insufficient data to estimate the coefficient precisely.\n",
        "\n",
        "\n",
        "## **Q20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?**\n",
        "\n",
        "Ans: Heteroscedasticity can be identified in residual plots by looking for the following patterns:\n",
        "\n",
        "**Patterns Indicative of Heteroscedasticity**\n",
        "\n",
        "**1. Fanning or cone-shaped pattern:**\n",
        "\n",
        "The residuals spread out or fan out as the fitted values increase, indicating that the variance of the residuals increases with the level of the independent variable.\n",
        "\n",
        "**2. Non-random pattern:**\n",
        "\n",
        "The residuals display a non-random pattern, such as a curve or a wave, indicating that the variance of the residuals changes with the level of the independent variable.\n",
        "\n",
        "**3. Increasing or decreasing variance:**\n",
        "\n",
        "The variance of the residuals increases or decreases as the fitted values increase, indicating that the variance of the residuals is not constant.\n",
        "\n",
        "**Importance of Addressing Heteroscedasticity**\n",
        "\n",
        "1. Inaccurate inference: Heteroscedasticity can lead to inaccurate inference and hypothesis testing, as the standard errors of the regression coefficients may be biased.\n",
        "\n",
        "2. Poor predictions: Heteroscedasticity can lead to poor predictions, as the model may not accurately capture the underlying relationship between the variables.\n",
        "\n",
        "3. Model misspecification: Heteroscedasticity can be a sign of model misspecification, indicating that the model is not capturing the underlying relationships between the variables.\n",
        "\n",
        "\n",
        "## **Q21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?**\n",
        "\n",
        "Ans: If a Multiple Linear Regression (MLR) model has a high R² but low adjusted R², it may indicate the following:\n",
        "\n",
        "**High R²:**\n",
        "\n",
        "1. Good fit: The model is fitting the data well, and the independent variables are explaining a significant amount of variation in the dependent variable.\n",
        "\n",
        "\n",
        "2. Overfitting: The model may be overfitting the data, meaning it is fitting the noise in the data rather than the underlying pattern.\n",
        "\n",
        "\n",
        "**Low Adjusted R²:**\n",
        "\n",
        "1. Penalty for complexity: The adjusted R² penalizes the model for its complexity, which means that the model may have too many independent variables or interactions.\n",
        "\n",
        "2. Inadequate explanatory power: The adjusted R² suggests that the model's explanatory power is not sufficient, considering the number of independent variables and the sample size.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **Q22. Why is it important to scale variables in Multiple Linear Regression?**\n",
        "\n",
        "Ans: Scaling variables in Multiple Linear Regression (MLR) is important for several reasons:\n",
        "\n",
        "**Reasons for Scaling Variables**\n",
        "\n",
        "1. Prevents Feature Dominance Scaling variables prevents features with large ranges from dominating the model. Without scaling, the model may give more weight to features with larger ranges, leading to biased results.\n",
        "\n",
        "2. Improves Model Interpretability Scaling variables makes it easier to interpret the model's coefficients. When all variables are on the same scale, the coefficients represent the change in the response variable for a one-unit change in the predictor variable.\n",
        "\n",
        "3. Enhances Numerical Stability Scaling variables improves numerical stability by reducing the risk of overflow or underflow errors. This is particularly important when working with large datasets or using algorithms that involve matrix operations.\n",
        "\n",
        "4. Facilitates Model Selection and Hyperparameter Tuning Scaling variables makes it easier to compare models with different sets of features or hyperparameters. This is because the scaled variables are on the same footing, allowing for more accurate comparisons.\n",
        "\n",
        "5. Supports Regularization Techniques Scaling variables is essential when using regularization techniques, such as Lasso or Ridge regression. These techniques rely on the variables being on the same scale to effectively penalize large coefficients.\n",
        "\n",
        "\n",
        "## **Q23. What is polynomial regression?**\n",
        "\n",
        "Ans: Polynomial regression is a type of regression analysis in which the relationship between the independent variable(s) and the dependent variable is modeled using a polynomial equation.\n",
        "\n",
        "**Polynomial Equation**\n",
        "\n",
        "A polynomial equation is an equation of the form:\n",
        "\n",
        "y = β0 + β1x + β2x² + β3x³ + … + βnx^n + ε\n",
        "\n",
        "where:\n",
        "\n",
        "y is the dependent variable\n",
        "\n",
        "x is the independent variable\n",
        "\n",
        "β0, β1, β2, …, βn are the coefficients of the polynomial equation\n",
        "\n",
        "n is the degree of the polynomial equation\n",
        "\n",
        "ε is the error term\n",
        "\n",
        "\n",
        "\n",
        "## **Q24. How does polynomial regression differ from linear regression?**\n",
        "\n",
        "Ans: Polynomial regression and linear regression are both types of regression analysis, but they differ in several key ways:\n",
        "\n",
        "Differences Between Polynomial Regression and Linear Regression\n",
        "\n",
        "1. Model Form\n",
        "\n",
        "Linear Regression: y = β0 + β1x + ε (straight line)\n",
        "\n",
        "Polynomial Regression: y = β0 + β1x + β2x² + … + βnx^n + ε (curved line)\n",
        "\n",
        "2. Relationship Between Variables\n",
        "\n",
        "Linear Regression: Assumes a linear relationship between the independent variable(s) and the dependent variable.\n",
        "\n",
        "Polynomial Regression: Assumes a non-linear relationship between the independent variable(s) and the dependent variable.\n",
        "\n",
        "3. Degree of Polynomial\n",
        "\n",
        "Linear Regression: Degree of polynomial is 1 (straight line).\n",
        "\n",
        "Polynomial Regression: Degree of polynomial can be 2 or higher (curved line).\n",
        "\n",
        "4. Complexity of Model\n",
        "\n",
        "Linear Regression: Simplest form of regression analysis.\n",
        "\n",
        "Polynomial Regression: More complex than linear regression, especially with higher-degree polynomials.\n",
        "\n",
        "5. Interpretation of Coefficients\n",
        "\n",
        "Linear Regression: Coefficients represent the change in the dependent variable for a one-unit change in the independent variable.\n",
        "\n",
        "Polynomial Regression: Coefficients represent the change in the dependent variable for a one-unit change in the independent variable, but the interpretation is more complex due to the non-linear relationship.\n",
        "\n",
        "6. Risk of Overfitting\n",
        "\n",
        "Linear Regression: Less risk of overfitting due to the simplicity of the model.\n",
        "\n",
        "Polynomial Regression: Higher risk of overfitting, especially with higher-degree polynomials.\n",
        "\n",
        "7. Computational Complexity\n",
        "\n",
        "Linear Regression: Computationally simple.\n",
        "\n",
        "Polynomial Regression: Computationally more complex, especially with higher-degree polynomials.\n",
        "\n",
        "8. Choosing Between Polynomial Regression and Linear Regression\n",
        "\n",
        "Use Linear Regression: When the relationship between the variables is linear, and the goal is to model a simple relationship.\n",
        "\n",
        "Use Polynomial Regression: When the relationship between the variables is non-linear, and the goal is to model a more complex relationship.\n",
        "\n",
        "## **Q25. When is polynomial regression used?**\n",
        "\n",
        "Ans: Polynomial regression is used in a variety of situations, including:\n",
        "\n",
        "**When to Use Polynomial Regression**\n",
        "\n",
        "1. Non-linear relationships: When the relationship between the independent variable(s) and the dependent variable is non-linear, polynomial regression can be used to model the relationship.\n",
        "\n",
        "2. Curvilinear relationships: When the relationship between the variables is curvilinear, polynomial regression can be used to model the relationship.\n",
        "\n",
        "3. Complex systems: When modeling complex systems, such as population growth or chemical reactions, polynomial regression can be used to capture the underlying dynamics.\n",
        "\n",
        "4. Data with outliers: When the data contains outliers, polynomial regression can be used to model the relationship while reducing the impact of the outliers.\n",
        "\n",
        "5. Modeling seasonal data: Polynomial regression can be used to model seasonal data, such as temperature or sales data, where the relationship between the variables changes over time.\n",
        "\n",
        "6. Predicting continuous outcomes: Polynomial regression can be used to predict continuous outcomes, such as stock prices or energy consumption.\n",
        "\n",
        "7. Modeling dose-response relationships: Polynomial regression can be used to model dose-response relationships in fields such as pharmacology or toxicology.\n",
        "\n",
        "\n",
        "## **Q26. What is the general equation for polynomial regression?**\n",
        "\n",
        "Ans: The general equation for polynomial regression is:\n",
        "\n",
        "y = β0 + β1x + β2x² + β3x³ + … + βnx^n + ε\n",
        "\n",
        "where:\n",
        "\n",
        "y is the dependent variable (response variable)\n",
        "\n",
        "x is the independent variable (predictor variable)\n",
        "\n",
        "β0, β1, β2, …, βn are the coefficients of the polynomial equation\n",
        "\n",
        "n is the degree of the polynomial equation (e.g., linear, quadratic, cubic, etc.)\n",
        "\n",
        "ε is the error term (residual)\n",
        "\n",
        "This equation can be expanded to include multiple independent variables, interactions between variables, and other terms.\n",
        "\n",
        "Linear Polynomial Regression (Degree 1):\n",
        "\n",
        "y = β0 + β1x + ε\n",
        "\n",
        "Quadratic Polynomial Regression (Degree 2):\n",
        "\n",
        "y = β0 + β1x + β2x² + ε\n",
        "\n",
        "Cubic Polynomial Regression (Degree 3):\n",
        "\n",
        "y = β0 + β1x + β2x² + β3x³ + ε\n",
        "\n",
        "And so on.\n",
        "\n",
        "## **Q27. Can polynomial regression be applied to multiple variables?**\n",
        "\n",
        "Ans: Yes, polynomial regression can be applied to multiple variables. This is known as multivariate polynomial regression.\n",
        "\n",
        "**Multivariate Polynomial Regression**\n",
        "\n",
        "In multivariate polynomial regression, the dependent variable (y) is modeled as a function of multiple independent variables (x1, x2, ..., xn) using a polynomial equation.\n",
        "\n",
        "The general equation for multivariate polynomial regression is:\n",
        "\n",
        "y = β0 + β11x1 + β12x1² + … + β1nx1^n + β21x2 + β22x2² + … + β2nx2^n + … + βn1xn + βn2xn² + … + βnnxn^n + ε\n",
        "\n",
        "where:\n",
        "\n",
        "y is the dependent variable\n",
        "\n",
        "x1, x2, ..., xn are the independent variables\n",
        "\n",
        "β0, β11, β12, …, βnn are the coefficients of the polynomial equation\n",
        "\n",
        "n is the degree of the polynomial equation\n",
        "\n",
        "ε is the error term\n",
        "\n",
        "\n",
        "## **Q28. What are the limitations of polynomial regression?**\n",
        "\n",
        "Ans: Polynomial regression has several limitations:\n",
        "\n",
        "**Limitations of Polynomial Regression**\n",
        "\n",
        "1. Overfitting\n",
        "\n",
        "Polynomial regression can easily overfit the data, especially when using high-degree polynomials. Overfitting occurs when the model is too complex and fits the noise in the data rather than the underlying pattern.\n",
        "\n",
        "2. Multicollinearity\n",
        "\n",
        "Polynomial regression can suffer from multicollinearity, especially when using high-degree polynomials. Multicollinearity occurs when the independent variables are highly correlated with each other, leading to unstable estimates of the coefficients.\n",
        "\n",
        "3. Computational Complexity\n",
        "\n",
        "Polynomial regression can be computationally complex, especially when dealing with large datasets or high-degree polynomials. This can lead to increased computational time and memory requirements.\n",
        "\n",
        "4. Difficulty in Model Selection\n",
        "\n",
        "Choosing the correct degree of the polynomial can be challenging, especially when dealing with complex data. A high-degree polynomial may overfit the data, while a low-degree polynomial may underfit the data.\n",
        "\n",
        "5. Interpretation of Coefficients\n",
        "\n",
        "Polynomial regression coefficients can be difficult to interpret, especially when dealing with high-degree polynomials. The coefficients may not have a clear physical meaning, making it challenging to understand the relationships between the variables.\n",
        "\n",
        "6. Non-Robustness to Outliers\n",
        "\n",
        "Polynomial regression can be sensitive to outliers in the data. Outliers can greatly impact the estimates of the coefficients, leading to inaccurate predictions.\n",
        "\n",
        "7. Limited Generalizability\n",
        "\n",
        "Polynomial regression models may not generalize well to new, unseen data. The model may be too specialized to the training data and may not capture the underlying patterns in the data.\n",
        "\n",
        "8. Difficulty in Handling Non-Numeric Data\n",
        "\n",
        "Polynomial regression can be challenging to apply to non-numeric data, such as categorical or text data. The model requires numeric inputs, which can limit its applicability to certain types of data.\n",
        "\n",
        "## **Q29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?**\n",
        "\n",
        "Ans: When selecting the degree of a polynomial, several methods can be used to evaluate model fit:\n",
        "\n",
        "**Methods to Evaluate Model Fit**\n",
        "\n",
        "1. Coefficient of Determination (R²): Measures the proportion of variance in the dependent variable that is explained by the polynomial model. A higher R² value indicates a better fit.\n",
        "\n",
        "2. Mean Squared Error (MSE): Measures the average squared difference between predicted and actual values. A lower MSE value indicates a better fit.\n",
        "\n",
        "3. Mean Absolute Error (MAE): Measures the average absolute difference between predicted and actual values. A lower MAE value indicates a better fit.\n",
        "\n",
        "4. Cross-Validation: Involves splitting the data into training and testing sets, fitting the model to the training set, and evaluating its performance on the testing set. This helps to prevent overfitting.\n",
        "\n",
        "5. Akaike Information Criterion (AIC): Measures the relative quality of a model for a given set of data. A lower AIC value indicates a better fit.\n",
        "\n",
        "6. Bayesian Information Criterion (BIC): Similar to AIC, but with a stronger penalty for complex models. A lower BIC value indicates a better fit.\n",
        "\n",
        "7. F-Statistic: Measures the ratio of the variance explained by the model to the variance of the residuals. A higher F-statistic value indicates a better fit.\n",
        "\n",
        "8. Residual Plots: Visualize the residuals to check for patterns, outliers, or non-normality. A random scatter of residuals around the horizontal axis indicates a good fit.\n",
        "\n",
        "9. Q-Q Plots: Compare the distribution of residuals to a normal distribution. A good fit is indicated by a straight line.\n",
        "\n",
        "\n",
        "## **Q30. Why is visualization important in polynomial regression?**\n",
        "\n",
        "Ans: Visualization is important in polynomial regression for several reasons:\n",
        "\n",
        "**Reasons for Visualization in Polynomial Regression**\n",
        "\n",
        "1. Understanding Relationships: Visualization helps to understand the relationships between the independent variable(s) and the dependent variable, including non-linear relationships.\n",
        "\n",
        "2. Model Evaluation: Visualization is essential for evaluating the fit of the polynomial model, including checking for overfitting, underfitting, and outliers.\n",
        "\n",
        "3. Identifying Patterns: Visualization can help identify patterns in the residuals, such as non-randomness, non-normality, or heteroscedasticity.\n",
        "\n",
        "4. Communicating Results: Visualization is an effective way to communicate the results of polynomial regression to non-technical stakeholders, including the relationships between variables and the fit of the model.\n",
        "\n",
        "## **Q31. How is polynomial regression implemented in Python?**\n",
        "\n",
        "Ans:\n",
        "\n"
      ],
      "metadata": {
        "id": "Nkw20XMkZLsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 1)\n",
        "y = 3 * X**2 + 2 * X + np.random.randn(100, 1)\n",
        "\n",
        "\n",
        "model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
        "\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "\n",
        "plt.scatter(X, y, label='Data')\n",
        "plt.plot(X, y_pred, label='Fitted curve', color='red')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "HrduYomGtoTT",
        "outputId": "4ac6baca-5e66-466b-8d4e-2bd7ff61ead4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}